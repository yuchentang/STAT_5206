---
title: "5206 Midterm"
author: "Yuchen Tang"
date: "3/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 0: Honor Code

```{r}
i_will_follow_the_honor_code <- TRUE
UNI <- "yt2754"
```

## Q1.0 Wrangle the VOO data
problem (1)
```{r}
library(tidyverse)
voo <- read_csv("alpha_vantage_voo_ts_daily.csv")
voo_days <- as.numeric(max(voo$dates) - min(voo$dates) + 1)
print(paste(voo_days, "days covered from the oldest to the newest"))
```
problem (2)
```{r}
voo_rows <- dim(voo)[1]
voo_cols <- dim(voo)[2]
print(paste0("Rows: ", voo_rows, ", Cols: ", voo_cols))
```
problem (3)
```{r}
voo <- voo %>%
  mutate(percent_change = (`adjusted close` - lead(`adjusted close`)) / `adjusted close`) %>%
  filter(!is.na(percent_change))
```

## Q1.1 Wrangle the VOO data
problem (1)
```{r}
avg_per <- mean(voo$percent_change)
sd_per <- sd(voo$percent_change)
print(paste0("average: ", round(avg_per, 5), ", standard deviation: ", round(sd_per, 5)))
```
problem (2)

Outliers: I want to define the records with the 0.5% biggest absolute values as outliers because the outliers may not be even in positive and negative intervals.
```{r}
outlier_threshold_abs <- quantile(sort(abs(voo$percent_change), decreasing = TRUE), 0.995)
voo <- voo %>%
  mutate(perc_change_outlier = (percent_change > outlier_threshold_abs | percent_change < (-outlier_threshold_abs)))
```
problem (3)
```{r}
print(paste0("Percent of outliers: ", 100 * round(sum(voo$perc_change_outlier) / nrow(voo), 3), "%"))
print(paste0("Number of outliers: ", sum(voo$perc_change_outlier), ", which is >= 5."))
cat("Outliers' values:", voo$percent_change[voo$perc_change_outlier == TRUE], ", which do cover both positive and negative values")
```
problem (4)
```{r}
outlier_dates <- voo$dates[voo$perc_change_outlier == TRUE]
print("Outliers' dates: ")
print(outlier_dates)
```

## Q2.0 Wrangle the News Data

```{r}
library(lubridate)
library(stringr)
library(jsonlite)
nytimes <- jsonlite::read_json("nytimes_filtered_article_2010_2020.json")
# get dates
get_date <- function(article){
  date <- article$pub_date %>% ymd_hms() %>% ceiling_date("day") %>% as.character()
  return(date)
}
dates <- map_chr(nytimes, get_date) #this line takes too much time!

# get sample_texts
get_sample_text <- function(article){
  sample_text <- paste(article$lead_paragraph, article$headline$main)
  return(sample_text)
}
sample_texts <- map_chr(nytimes, get_sample_text)

# get related2fin
tiny_get_related2fin <- function(keywords){
  if (str_detect(tolower(keywords$value), "econ") | str_detect(tolower(keywords$value), "stock")) {return (TRUE)}
  else {return (FALSE)}
}
get_related2fin <- function(article){
  related2fin <- map_lgl(article$keywords, tiny_get_related2fin)
  return(any(related2fin))
}
related2fins <- map_lgl(nytimes, get_related2fin)

# get news_desks
get_news_desk <- function(article){
  return(article$news_desk)
}
news_desks <- map_chr(nytimes, get_news_desk)

# generate the dataframe
nytimes_df <- data.frame(pub_date = dates, sample_text = sample_texts, related2fin = related2fins, news_desk = news_desks)
```

## Q2.1
problem (1)
```{r}
nytimes_df_rows <- dim(nytimes_df)[1]
nytimes_df_cols <- dim(nytimes_df)[2]
print(paste0("Rows: ", nytimes_df_rows, ", Cols: ", nytimes_df_cols))
```
problem (2)
```{r}
prop_related2fin <- nytimes_df %>%
  group_by(pub_date, news_desk) %>%
  summarize(prop = sum(related2fin == TRUE) / n()) %>%
  pivot_wider(names_from = news_desk, values_from = prop)
```
Since these NAs are generated due to no corresponding news_desk on a particular date, number "0" is acceptable for representing no articles related to finance (even if in fact there is no such news_desk at all!)
```{r}
prop_related2fin[is.na(prop_related2fin)] <- 0
```
problem (3)
```{r}
prop_related2fin_rows <- dim(prop_related2fin)[1]
prop_related2fin_cols <- dim(prop_related2fin)[2]
print(paste0("Rows: ", prop_related2fin_rows, ", Cols: ", prop_related2fin_cols))
print("The first 3 records are: ")
print(prop_related2fin[1:3, ])
```

## Q3 Data mining
problem (1)
```{r}
# extract outlier articles & non-outlier articles in nytimes_df (dataframe)
outlier_articles_df <- nytimes_df %>%
  filter(startsWith(pub_date, "2020-03"), related2fin == TRUE) %>%
  filter(pub_date %in% as.character(outlier_dates))
non_outlier_articles_df <- nytimes_df %>%
  filter(startsWith(pub_date, "2020-03"), related2fin == TRUE) %>%
  filter(!(pub_date %in% as.character(outlier_dates)))
#use their row indices to extract corresponding articles in nytimes (large list)
outlier_articles <- nytimes[row.names(outlier_articles_df)]
non_outlier_articles <- nytimes[row.names(non_outlier_articles_df)]
```
problem (2)
```{r}
#get all outlier articles' keywords
tiny_get_keyword <- function(keywords){
  return(keywords$value)
}
get_keyword <- function(article){
  return(map_chr(article$keywords, tiny_get_keyword))
}
uniq_outlier_keywords <- unique(flatten_chr(map(outlier_articles, get_keyword)))

#generate a dataframe of keywords & outlier articles, filling with 0
keywords_outlier_mat <- data.frame(
    matrix(0, 
           nrow = length(uniq_outlier_keywords), 
           ncol = length(outlier_articles)))
rownames(keywords_outlier_mat) <- uniq_outlier_keywords # row names
names(keywords_outlier_mat) <- names(outlier_articles) # col names
# add frequency into the dataframe by looping outlier articles
for (i in seq_along(outlier_articles)){
  target_keywords <- uniq_outlier_keywords %in% get_keyword(outlier_articles[[i]])
  keywords_outlier_mat[target_keywords, i] <- keywords_outlier_mat[target_keywords, i] + 1
}
#calculating proportion of different keywords
keywords_outlier_prop <- (keywords_outlier_mat %>% rowSums()) / length(outlier_articles)
```
problem (3)
```{r}
keywords_outlier_prop <- sort(keywords_outlier_prop, decreasing = TRUE)
print(keywords_outlier_prop[1:3])
```
problem(4)
```{r}
#almost same as (2)
#get all non-outlier articles' keywords
uniq_non_outlier_keywords <- unique(flatten_chr(map(non_outlier_articles, get_keyword)))

#generate a dataframe of keywords & non-outlier articles, filling with 0
keywords_non_outlier_mat <- data.frame(
    matrix(0, 
           nrow = length(uniq_non_outlier_keywords), 
           ncol = length(non_outlier_articles)))
rownames(keywords_non_outlier_mat) <- uniq_non_outlier_keywords # row names
names(keywords_non_outlier_mat) <- names(non_outlier_articles) # col names
# add frequency into the dataframe by looping non-outlier articles
for (i in seq_along(non_outlier_articles)){
  target_keywords <- uniq_non_outlier_keywords %in% get_keyword(non_outlier_articles[[i]])
  keywords_non_outlier_mat[target_keywords, i] <- keywords_non_outlier_mat[target_keywords, i] + 1
}
#calculating proportion of different keywords
keywords_non_outlier_prop <- (keywords_non_outlier_mat %>% rowSums()) / length(non_outlier_articles)
```
problem (5)
```{r}
keywords_non_outlier_prop <- sort(keywords_non_outlier_prop, decreasing = TRUE)
print(keywords_non_outlier_prop[1:3])
```
problem (6)

Since the keywords are not shared between the two groups, there are 2 kinds of ways to fix this. 1st is to expand the 2 proportion vectors with filling many additional "0", which would only generate more "0" or "NA" when calculating relative proportion and it is meaningless. So I decide to find the intersection of the two groups of keywords and cut the size of the two proportion vectors. 
```{r}
keywords_both <- intersect(names(keywords_non_outlier_prop), names(keywords_outlier_prop))
new_keywords_outlier_prop <- keywords_outlier_prop[keywords_both]
new_keywords_non_outlier_prop <- keywords_non_outlier_prop[keywords_both]
#Method 1 (for-loop):
relative_prop1 <- vector("numeric", length(keywords_both))
for (i in seq_along(relative_prop1)){
  relative_prop1[i] <- new_keywords_outlier_prop[i] / new_keywords_non_outlier_prop[i]
}

#Method 2 (no for-loop)
relative_prop2 <- new_keywords_outlier_prop / new_keywords_non_outlier_prop
```
problem (7)
```{r}
prop1_equal_prop2 <- all(sort(relative_prop1) == sort(relative_prop2))
if(prop1_equal_prop2) {print("The two approaches get the same answers!")}
```
problem (8)
```{r}
sorted_relative_prop <- sort(relative_prop2, decreasing = TRUE)
print(sorted_relative_prop[1:3])
```

